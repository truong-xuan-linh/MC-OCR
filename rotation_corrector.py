# -*- coding: utf-8 -*-
"""rotation corrector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pu_quTu23qS_gNam1Yri-fX-nLwM4L-s
"""

import numpy as np
import cv2
from keras.models import Sequential, Model,load_model
import math

def find_Longest_Box(boxes):
  max_distance = 0
  pos_box = None
  pos = 0
  for i, box in enumerate(boxes):
    A = np.array(box[0])
    B = np.array(box[1])
    C = np.array(box[2])
    distance1 = np.linalg.norm(A - B)
    distance2 = np.linalg.norm(B - C)
    pos1 = None
    pos2 = None
    if distance1 > distance2:
      pos1 = A
      pos2 = B
      distance = distance1
    else:
      pos1 = B
      pos2 = C
      distance = distance2
    if distance > max_distance:
      max_distance = distance
      pos_box = [pos1,pos2]
      pos = i + 1
  return pos_box

def calculate_Angle(pos):
  try: 
    A = pos[0]
    B = pos[1]
    vectorA = [B[0] - A[0], B[1] - A[1]]
    vectorB = [1,0]
    unit_vectorA = vectorA/np.linalg.norm(vectorA)
    unit_vectorB = vectorB/np.linalg.norm(vectorB)
    dot_product = np.dot(unit_vectorA, unit_vectorB)
    
    angle = np.arccos(dot_product)
    if vectorA[1] < 0:
      angle = -angle
  except:
    angle = 0
  return angle

def rotate_Image(img_dir, angle):
  try:
    image = cv2.imread(img_dir)
  except:
    image = img_dir
  #result = ocr_model.ocr(image)
  #boxes = [res[0] for res in result]
  #pos_box, _ = find_Longest_Box(boxes)
  #angle = calculate_Angle(pos_box)*180/math.pi 
  
  # grab the dimensions of the image and then determine the
  # center
  (h, w) = image.shape[:2]
  (cX, cY) = (w // 2, h // 2)
  # grab the rotation matrix (applying the negative of the
  # angle to rotate clockwise), then grab the sine and cosine
  # (i.e., the rotation components of the matrix)
  M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)
  cos = np.abs(M[0, 0])
  sin = np.abs(M[0, 1])
  # compute the new bounding dimensions of the image
  nW = int((h * sin) + (w * cos))
  nH = int((h * cos) + (w * sin))
  # adjust the rotation matrix to take into account translation
  M[0, 2] += (nW / 2) - cX
  M[1, 2] += (nH / 2) - cY
  # perform the actual rotation and return the image
  return cv2.warpAffine(image, M, (nW, nH))
model = load_model("./checkpoint/EfficientNetV2L_checkpoint.h5")
def rotated_image_predict(image):
  img = image.copy()
  rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  rgbImg = np.expand_dims(cv2.resize(rgbImg, (256,256)), axis = 0)/255
  pre = np.argmax(model.predict(rgbImg))
  return pre

